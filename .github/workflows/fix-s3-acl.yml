name: ğŸ›¡ï¸ S3 Security Gatekeeper (Debug)

on:
  push:
    branches: [ main, develop ]
    paths:
      - '**/*.tf'
      - '**/*.json'
      - '.github/workflows/s3-security.yml'
  pull_request:
    branches: [ main ]
    paths:
      - '**/*.tf'
      - '**/*.json'
  workflow_dispatch:
    inputs:
      scan_all:
        description: 'Scan all files (not just changed)'
        required: false
        default: 'false'
        type: boolean
      auto_fix:
        description: 'Auto-generate fixes for S3 issues'
        required: false
        default: 'true'
        type: boolean
      debug_mode:
        description: 'Enable debug output'
        required: false
        default: 'true'
        type: boolean

env:
  CHECKOV_VERSION: "3.2.0"
  PYTHON_VERSION: "3.11"
  DEBUG: ${{ github.event.inputs.debug_mode || 'true' }}

jobs:
  # Job 1: Run Checkov Security Scan
  security-scan:
    name: ğŸ” Security Scan
    runs-on: ubuntu-latest
    permissions:
      contents: read
      security-events: write
      pull-requests: write
    
    outputs:
      has-s3-issues: ${{ steps.check-s3-issues.outputs.has-issues }}
      scan-status: ${{ steps.checkov-scan.outputs.status }}
      s3-issues-count: ${{ steps.check-s3-issues.outputs.issues-count }}
      scan-completed: ${{ steps.checkov-scan.outputs.completed }}
    
    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: ğŸ“¦ Install Checkov
        run: |
          pip install checkov==${{ env.CHECKOV_VERSION }}
          checkov --version

      - name: ğŸ“ Create Reports Directory
        run: |
          mkdir -p checkov_reports scripts
          echo "Created directories:"
          ls -la checkov_reports/ scripts/

      - name: ğŸ” Debug - List Terraform Files
        if: env.DEBUG == 'true'
        run: |
          echo "=== Terraform files found ==="
          find . -name "*.tf" -type f | head -20
          echo "=== File count ==="
          find . -name "*.tf" -type f | wc -l

      - name: ğŸ” Run Checkov Scan
        id: checkov-scan
        continue-on-error: true
        run: |
          echo "ğŸ” Running Checkov security scan..."
          
          # Ensure reports directory exists
          mkdir -p checkov_reports
          
          # Check if we have any Terraform files
          TF_FILES=$(find . -name "*.tf" -type f | wc -l)
          echo "Found $TF_FILES Terraform files"
          
          if [ "$TF_FILES" -eq 0 ]; then
            echo "âš ï¸ No Terraform files found - creating empty report"
            echo '{"results": {"failed_checks": [], "passed_checks": []}}' > checkov_reports/report.json
            echo "status=no_tf_files" >> $GITHUB_OUTPUT
            echo "completed=true" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Run Checkov with JSON output
          CHECKOV_EXIT_CODE=0
          checkov \
            --framework terraform \
            --output json \
            --output-file checkov_reports/report.json \
            --directory . \
            --skip-check CKV_TF_1 \
            --verbose || CHECKOV_EXIT_CODE=$?
          
          echo "checkov_exit_code=$CHECKOV_EXIT_CODE" >> $GITHUB_OUTPUT
          
          # Verify the report was created
          if [ ! -f "checkov_reports/report.json" ]; then
            echo "âŒ Checkov report not created - generating empty report"
            echo '{"results": {"failed_checks": [], "passed_checks": []}}' > checkov_reports/report.json
          fi
          
          # Also generate CLI output for logs
          echo "=== Checkov CLI Output ==="
          checkov \
            --framework terraform \
            --directory . \
            --compact || true
          
          echo "status=completed" >> $GITHUB_OUTPUT
          echo "completed=true" >> $GITHUB_OUTPUT

      - name: ğŸ” Debug - Show Checkov Report
        if: env.DEBUG == 'true'
        run: |
          echo "=== Directory Contents ==="
          ls -la checkov_reports/ || echo "checkov_reports directory not found"
          
          echo "=== Checkov Report Contents ==="
          if [ -f "checkov_reports/report.json" ]; then
            echo "Report file exists, size: $(wc -c < checkov_reports/report.json) bytes"
            echo "First 2000 characters:"
            head -c 2000 checkov_reports/report.json
            echo -e "\n=== Report structure ==="
            python3 -c "
          import json
          import sys
          try:
              with open('checkov_reports/report.json', 'r') as f:
                  data = json.load(f)
              print('Report type:', type(data))
              if isinstance(data, dict):
                  print('Keys:', list(data.keys()))
                  if 'results' in data:
                      results = data['results']
                      print('Results type:', type(results))
                      if isinstance(results, dict):
                          print('Results keys:', list(results.keys()))
                          if 'failed_checks' in results:
                              print('Failed checks count:', len(results['failed_checks']))
                          if 'passed_checks' in results:
                              print('Passed checks count:', len(results['passed_checks']))
                  elif 'failed_checks' in data:
                      print('Failed checks count:', len(data['failed_checks']))
              elif isinstance(data, list):
                  print('List length:', len(data))
                  if len(data) > 0:
                      print('First item keys:', list(data[0].keys()) if isinstance(data[0], dict) else 'Not a dict')
          except Exception as e:
              print('Error parsing report:', e)
              import traceback
              traceback.print_exc()
          "
          else
            echo "âŒ Report file not found!"
            echo "Files in current directory:"
            find . -name "*.json" -o -name "report*" | head -10
          fi

      - name: ğŸ“Š Check for S3 Issues
        id: check-s3-issues
        run: |
          cat > scripts/check_s3_issues.py << 'EOF'
          import json
          import sys
          from pathlib import Path
          
          def main():
              report_path = Path("checkov_reports/report.json")
              if not report_path.exists():
                  print("âŒ No Checkov report found", file=sys.stderr)
                  print("has-issues=false")
                  print("issues-count=0")
                  return
              
              try:
                  with open(report_path, 'r') as f:
                      data = json.load(f)
                  
                  failed_checks = []
                  
                  # Handle different Checkov report formats
                  if isinstance(data, dict):
                      if 'results' in data:
                          results = data['results']
                          if isinstance(results, dict) and 'failed_checks' in results:
                              failed_checks = results['failed_checks']
                          elif isinstance(results, list):
                              for result in results:
                                  if isinstance(result, dict) and 'failed_checks' in result:
                                      failed_checks.extend(result['failed_checks'])
                      elif 'failed_checks' in data:
                          failed_checks = data['failed_checks']
                  elif isinstance(data, list):
                      for item in data:
                          if isinstance(item, dict):
                              if 'results' in item and isinstance(item['results'], dict) and 'failed_checks' in item['results']:
                                  failed_checks.extend(item['results']['failed_checks'])
                              elif 'failed_checks' in item:
                                  failed_checks.extend(item['failed_checks'])
                  
                  print(f"Total failed checks found: {len(failed_checks)}", file=sys.stderr)
                  
                  # S3 security checks we're targeting
                  s3_checks = [
                      'CKV_AWS_20',  # S3 Bucket has an ACL defined which allows public access
                      'CKV2_AWS_6',  # S3 bucket has S3 Bucket Public Access Block enabled
                      'CKV_AWS_21',  # S3 bucket has server-side encryption enabled
                      'CKV_AWS_18',  # S3 bucket has access logging enabled
                      'CKV_AWS_19',  # S3 bucket has MFA delete enabled
                      'CKV_AWS_54',  # S3 bucket has block public policy enabled
                      'CKV_AWS_55',  # S3 bucket has ignore public ACLs enabled
                      'CKV_AWS_56'   # S3 bucket has restrict public bucket policies enabled
                  ]
                  
                  s3_issues = []
                  for check in failed_checks:
                      check_id = check.get('check_id', '')
                      if check_id in s3_checks:
                          s3_issues.append(check)
                          print(f"Found S3 issue: {check_id} in {check.get('file_path', 'unknown')}", file=sys.stderr)
                  
                  print(f"S3 issues found: {len(s3_issues)}", file=sys.stderr)
                  
                  # Force has-issues to true for testing if debug mode is on
                  if len(s3_issues) > 0:
                      print("has-issues=true")
                  else:
                      # For debugging - you can uncomment this to force generation
                      # print("has-issues=true")  # Force true for testing
                      print("has-issues=false")
                  
                  print(f"issues-count={len(s3_issues)}")
                  
                  # Debug: show all check IDs found
                  all_check_ids = sorted(set(check.get('check_id', '') for check in failed_checks))
                  print(f"All check IDs found: {all_check_ids}", file=sys.stderr)
                  
                  # Show sample of failed checks for debugging
                  if failed_checks:
                      print("Sample failed checks:", file=sys.stderr)
                      for i, check in enumerate(failed_checks[:3]):
                          print(f"  {i+1}. {check.get('check_id', 'N/A')} - {check.get('check_name', 'N/A')}", file=sys.stderr)
                  
              except Exception as e:
                  print(f"Error processing report: {e}", file=sys.stderr)
                  import traceback
                  traceback.print_exc(file=sys.stderr)
                  print("has-issues=false")
                  print("issues-count=0")
          
          if __name__ == "__main__":
              main()
          EOF
          
          # Run the check and capture outputs
          python scripts/check_s3_issues.py >> $GITHUB_OUTPUT
          echo "ğŸ” S3 Issues Check completed"

      - name: ğŸ“¤ Upload Scan Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: checkov-scan-results
          path: |
            checkov_reports/
            scripts/
          retention-days: 30
          if-no-files-found: warn

  # Job 2: Generate Reports and Fixes
  generate-fixes:
    name: ğŸ”§ Generate S3 Fixes
    runs-on: ubuntu-latest
    needs: security-scan
    # Modified condition to always run if scan completed successfully
    if: always() && needs.security-scan.outputs.scan-completed == 'true'
    permissions:
      contents: write
      pull-requests: write
    
    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: ğŸ“ Create Scripts Directory
        run: mkdir -p scripts fixed_terraform

      - name: ğŸ“¥ Download Scan Results
        uses: actions/download-artifact@v4
        with:
          name: checkov-scan-results
          path: ./

      - name: ğŸ” Debug - Verify Downloaded Files
        if: env.DEBUG == 'true'
        run: |
          echo "=== Downloaded files ==="
          find . -name "*.json" -o -name "*.py" -o -name "*.md" | head -20
          if [ -f "checkov_reports/report.json" ]; then
            echo "Report size: $(wc -c < checkov_reports/report.json) bytes"
          fi

      - name: ğŸ“ Generate Markdown Report
        run: |
          cat > scripts/generate_reports.py << 'EOF'
          #!/usr/bin/env python3
          import json
          import os
          from datetime import datetime
          from pathlib import Path
          
          def load_checkov_report():
              report_path = Path("checkov_reports/report.json")
              if not report_path.exists():
                  print("âŒ No Checkov report found")
                  return None
              try:
                  with open(report_path, 'r') as f:
                      return json.load(f)
              except Exception as e:
                  print(f"Error loading report: {e}")
                  return None
          
          def parse_checkov_data(data):
              failed_checks = []
              if isinstance(data, dict):
                  if "results" in data:
                      results = data["results"]
                      if isinstance(results, dict) and "failed_checks" in results:
                          failed_checks = results["failed_checks"]
                      elif isinstance(results, list):
                          for result in results:
                              if isinstance(result, dict) and "failed_checks" in result:
                                  failed_checks.extend(result["failed_checks"])
                  elif "failed_checks" in data:
                      failed_checks = data.get("failed_checks", [])
              elif isinstance(data, list):
                  for item in data:
                      if isinstance(item, dict):
                          if "results" in item and isinstance(item["results"], dict) and "failed_checks" in item["results"]:
                              failed_checks.extend(item["results"]["failed_checks"])
                          elif "failed_checks" in item:
                              failed_checks.extend(item["failed_checks"])
              return failed_checks
          
          def generate_summary_report(failed_checks):
              s3_checks = ['CKV_AWS_20', 'CKV2_AWS_6', 'CKV_AWS_21', 'CKV_AWS_18', 'CKV_AWS_19', 'CKV_AWS_54', 'CKV_AWS_55', 'CKV_AWS_56']
              s3_issues = [check for check in failed_checks if check.get('check_id') in s3_checks]
              
              report = f"""# ğŸ›¡ï¸ S3 Security Scan Summary
          
          **Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}
          **Commit:** {os.environ.get('GITHUB_SHA', 'unknown')[:8]}
          **Branch:** {os.environ.get('GITHUB_REF_NAME', 'unknown')}
          
          ## ğŸ“Š Results
          
          - **Total Failed Checks:** {len(failed_checks)}
          - **S3 Security Issues:** {len(s3_issues)} {'ğŸš¨' if s3_issues else 'âœ…'}
          - **Status:** {'âŒ Issues Found' if s3_issues else 'âœ… No S3 Issues'}
          
          ## ğŸš¨ S3 Issues Found
          
          """
              
              if not s3_issues:
                  report += "âœ… **No S3 security issues detected!**\n\n"
                  if failed_checks:
                      report += f"However, {len(failed_checks)} other security issues were found.\n\n"
              else:
                  for i, issue in enumerate(s3_issues, 1):
                      report += f"""### {i}. {issue.get('check_name', 'Unknown Check')}
          
          - **Check ID:** `{issue.get('check_id', 'N/A')}`
          - **File:** `{issue.get('file_path', 'N/A')}`
          - **Resource:** `{issue.get('resource', 'N/A')}`
          - **Lines:** {'-'.join(map(str, issue.get('file_line_range', ['N/A'])))}
          - **Description:** {issue.get('description', 'N/A')}
          
          """
              
              # Debug info
              all_check_ids = sorted(set(check.get('check_id', 'N/A') for check in failed_checks))
              report += f"""
          ## ğŸ” Debug Information
          
          - **All Check IDs Found:** {', '.join(all_check_ids) if all_check_ids else 'None'}
          - **S3 Check IDs Monitored:** {', '.join(s3_checks)}
          - **Files Scanned:** {len(set(check.get('file_path', 'N/A') for check in failed_checks))}
          - **Total Issues:** {len(failed_checks)}
          
          ## ğŸ”§ Next Steps
          
          {'1. Review the generated fixes in the `fixed_terraform/` directory' if s3_issues else ''}
          {'2. Apply the security improvements to make S3 buckets private' if s3_issues else ''}
          {'3. Re-run the security scan to verify fixes' if s3_issues else ''}
          {'' if s3_issues else '1. Review other security issues found in the scan'}
          {'' if s3_issues else '2. Check the Checkov report for details on non-S3 issues'}
          
          ---
          *Generated by S3 Security Gatekeeper*
          """
              
              return report
          
          def main():
              data = load_checkov_report()
              if not data:
                  print("No Checkov data found")
                  return
              
              failed_checks = parse_checkov_data(data)
              report = generate_summary_report(failed_checks)
              
              # Ensure directory exists
              os.makedirs("checkov_reports", exist_ok=True)
              
              with open("checkov_reports/security_summary.md", "w") as f:
                  f.write(report)
              
              print(f"Generated summary report with {len(failed_checks)} total issues")
          
          if __name__ == "__main__":
              main()
          EOF
          
          python scripts/generate_reports.py

      - name: ğŸ”§ Generate S3 Fixes
        run: |
          cat > scripts/fix_s3_buckets.py << 'EOF'
          #!/usr/bin/env python3
          import json
          import os
          import re
          from pathlib import Path
          from datetime import datetime
          
          S3_PUBLIC_CHECKS = {
              "CKV_AWS_20": "S3 Bucket has an ACL defined which allows public access",
              "CKV2_AWS_6": "Ensure that S3 bucket has S3 Bucket Public Access Block enabled",
              "CKV_AWS_21": "Ensure S3 bucket has server-side encryption enabled",
              "CKV_AWS_18": "Ensure S3 bucket has access logging enabled",
              "CKV_AWS_19": "Ensure S3 bucket has MFA delete enabled",
              "CKV_AWS_54": "Ensure S3 bucket has block public policy enabled",
              "CKV_AWS_55": "Ensure S3 bucket has ignore public ACLs enabled",
              "CKV_AWS_56": "Ensure S3 bucket has restrict public bucket policies enabled"
          }
          
          def load_checkov_report():
              report_path = Path("checkov_reports/report.json")
              if not report_path.exists():
                  print("âŒ No Checkov report found")
                  return None
              try:
                  with open(report_path, 'r') as f:
                      return json.load(f)
              except Exception as e:
                  print(f"Error loading report: {e}")
                  return None
          
          def parse_checkov_data(data):
              failed_checks = []
              if isinstance(data, dict):
                  if "results" in data:
                      results = data["results"]
                      if isinstance(results, dict) and "failed_checks" in results:
                          failed_checks = results["failed_checks"]
                      elif isinstance(results, list):
                          for result in results:
                              if isinstance(result, dict) and "failed_checks" in result:
                                  failed_checks.extend(result["failed_checks"])
                  elif "failed_checks" in data:
                      failed_checks = data.get("failed_checks", [])
              elif isinstance(data, list):
                  for item in data:
                      if isinstance(item, dict):
                          if "results" in item and isinstance(item["results"], dict) and "failed_checks" in item["results"]:
                              failed_checks.extend(item["results"]["failed_checks"])
                          elif "failed_checks" in item:
                              failed_checks.extend(item["failed_checks"])
              return failed_checks
          
          def identify_s3_issues(failed_checks):
              return [check for check in failed_checks if check.get("check_id") in S3_PUBLIC_CHECKS]
          
          def extract_bucket_name(resource_name):
              """Extract bucket name from resource identifier"""
              if '.' in resource_name:
                  return resource_name.split('.')[-1]
              return resource_name.replace('aws_s3_bucket.', '').replace('_acl', '').replace('_bucket', '')
          
          def fix_terraform_content(content, resource_name, check_id):
              try:
                  bucket_name = extract_bucket_name(resource_name)
                  
                  if check_id == "CKV_AWS_20":  # Fix public ACL
                      patterns = [
                          (r'acl\s*=\s*"public-read"', 'acl = "private"'),
                          (r'acl\s*=\s*"public-read-write"', 'acl = "private"'),
                      ]
                      for pattern, replacement in patterns:
                          content = re.sub(pattern, replacement, content, flags=re.IGNORECASE)
                  
                  elif check_id in ["CKV2_AWS_6", "CKV_AWS_54", "CKV_AWS_55", "CKV_AWS_56"]:  # Add public access block
                      pab_config = f'''

# Added by S3 Security Gatekeeper
resource "aws_s3_bucket_public_access_block" "{bucket_name}_pab" {{
  bucket = aws_s3_bucket.{bucket_name}.id

  block_public_acls       = true
  block_public_policy     = true
  ignore_public_acls      = true
  restrict_public_buckets = true
}}'''
                      if f'{bucket_name}_pab' not in content and 'aws_s3_bucket_public_access_block' not in content:
                          content += pab_config
                  
                  elif check_id == "CKV_AWS_21":  # Add encryption
                      encrypt_config = f'''

# Added by S3 Security Gatekeeper
resource "aws_s3_bucket_server_side_encryption_configuration" "{bucket_name}_encryption" {{
  bucket = aws_s3_bucket.{bucket_name}.id

  rule {{
    apply_server_side_encryption_by_default {{
      sse_algorithm = "AES256"
    }}
  }}
}}'''
                      if f'{bucket_name}_encryption' not in content:
                          content += encrypt_config
                  
                  elif check_id == "CKV_AWS_18":  # Add access logging
                      logging_config = f'''

# Added by S3 Security Gatekeeper
resource "aws_s3_bucket" "{bucket_name}_logs" {{
  bucket = "{bucket_name}-access-logs"
}}

resource "aws_s3_bucket_logging" "{bucket_name}_logging" {{
  bucket = aws_s3_bucket.{bucket_name}.id

  target_bucket = aws_s3_bucket.{bucket_name}_logs.id
  target_prefix = "access-logs/"
}}'''
                      if f'{bucket_name}_logging' not in content:
                          content += logging_config
                  
                  elif check_id == "CKV_AWS_19":  # Add versioning
                      versioning_config = f'''

# Added by S3 Security Gatekeeper
resource "aws_s3_bucket_versioning" "{bucket_name}_versioning" {{
  bucket = aws_s3_bucket.{bucket_name}.id
  versioning_configuration {{
    status = "Enabled"
  }}
}}'''
                      if f'{bucket_name}_versioning' not in content:
                          content += versioning_config
                  
                  return content
              except Exception as e:
                  print(f"Error in fix_terraform_content: {e}")
                  return content
          
          def main():
              print("ğŸ”§ Starting S3 fixes generation...")
              
              data = load_checkov_report()
              if not data:
                  print("No Checkov data found")
                  return
              
              failed_checks = parse_checkov_data(data)
              s3_issues = identify_s3_issues(failed_checks)
              
              print(f"ğŸ” Total failed checks: {len(failed_checks)}")
              print(f"ğŸ” S3 issues found: {len(s3_issues)}")
              
              # Create fixed directory
              fixed_dir = Path("fixed_terraform")
              fixed_dir.mkdir(exist_ok=True)
              
              if not s3_issues:
                  print("âœ… No S3 issues to fix")
                  # Still create a summary file
                  summary_content = f"""# ğŸ”§ S3 Security Fixes Summary

**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}
**Status:** âœ… No S3 issues found to fix

## ğŸ“Š Scan Results
- **Total Issues:** {len(failed_checks)}
- **S3 Issues:** 0

---
*Generated by S3 Security Gatekeeper*
"""
                  
                  with open(fixed_dir / "FIXES_SUMMARY.md", "w") as f:
                      f.write(summary_content)
                  
                  return
              
              files_processed = set()
              
              for issue in s3_issues:
                  file_path = issue.get("file_path", "")
                  if not file_path or not os.path.exists(file_path):
                      print(f"âš ï¸ Skipping missing file: {file_path}")
                      continue
                  
                  if file_path in files_processed:
                      continue
                  
                  print(f"ğŸ”§ Processing {file_path}")
                  
                  try:
                      with open(file_path, 'r', encoding='utf-8') as f:
                          content = f.read()
                      
                      original_content = content
                      
                      # Apply all fixes for this file
                      file_issues = [i for i in s3_issues if i.get("file_path") == file_path]
                      for file_issue in file_issues:
                          resource_name = file_issue.get("resource", "")
                          check_id = file_issue.get("check_id", "")
                          print(f"  Applying fix for {check_id}: {S3_PUBLIC_CHECKS.get(check_id, 'Unknown')}")
                          content = fix_terraform_content(content, resource_name, check_id)
                      
                      # Only write if content changed
                      if content != original_content:
                          output_path = fixed_dir / os.path.basename(file_path)
                          with open(output_path, 'w', encoding='utf-8') as f:
                              f.write(content)
                          print(f"  âœ… Fixed version saved to: {output_path}")
                      else:
                          print(f"  âš ï¸ No changes made to {file_path}")
                      
                      files_processed.add(file_path)
                      
                  except Exception as e:
                      print(f"  âŒ Error processing {file_path}: {e}")
                      import traceback
                      traceback.print_exc()
              
              # Generate summary
              summary_content = f"""# ğŸ”§ S3 Security Fixes Applied

**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}
**Files Processed:** {len(files_processed)}
**Issues Fixed:** {len(s3_issues)}

## ğŸ“‹ Fixes Applied

"""
              
              for issue in s3_issues:
                  file_path = issue.get("file_path", "N/A")
                  check_id = issue.get("check_id", "N/A")
                  resource = issue.get("resource", "N/A")
                  description = S3_PUBLIC_CHECKS.get(check_id, "Unknown check")
                  
                  summary_content += f"""### {check_id}
- **File:** `{file_path}`
- **Resource:** `{resource}`
- **Fix:** {description}

"""
              
              # Continue from where the fix_s3_buckets.py script was cut off
      
              summary_content += """
          ## ğŸš€ Next Steps
          
          1. Review the fixed Terraform files in the `fixed_terraform/` directory
          2. Compare the changes with your original files
          3. Apply the security improvements to your infrastructure
          4. Re-run the security scan to verify fixes
          
          ---
          *Generated by S3 Security Gatekeeper*
          """
              
              with open(fixed_dir / "FIXES_SUMMARY.md", "w") as f:
                  f.write(summary_content)
              
              print(f"âœ… Generated fixes for {len(s3_issues)} S3 issues across {len(files_processed)} files")
          
          if __name__ == "__main__":
              main()
          EOF
          
          python scripts/fix_s3_buckets.py

      - name: ğŸ“Š Display Fix Summary
        run: |
          echo "=== Fix Generation Summary ==="
          if [ -d "fixed_terraform" ]; then
            echo "Fixed files generated:"
            ls -la fixed_terraform/
            echo ""
            if [ -f "fixed_terraform/FIXES_SUMMARY.md" ]; then
              echo "=== Fixes Summary ==="
              cat fixed_terraform/FIXES_SUMMARY.md
            fi
          else
            echo "No fixes directory created"
          fi

      - name: ğŸ“ Comment on PR
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');
            
            let comment = '## ğŸ›¡ï¸ S3 Security Scan Results\n\n';
            
            // Add security summary if it exists
            const summaryPath = 'checkov_reports/security_summary.md';
            if (fs.existsSync(summaryPath)) {
              const summary = fs.readFileSync(summaryPath, 'utf8');
              comment += summary + '\n\n';
            }
            
            // Add fixes summary if it exists
            const fixesPath = 'fixed_terraform/FIXES_SUMMARY.md';
            if (fs.existsSync(fixesPath)) {
              const fixes = fs.readFileSync(fixesPath, 'utf8');
              comment += '---\n\n' + fixes;
            }
            
            // Add workflow run link
            comment += `\n\n---\nğŸ“Š [View detailed workflow run](${context.payload.repository.html_url}/actions/runs/${context.runId})`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

      - name: ğŸ“¤ Upload Fix Artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: s3-security-fixes
          path: |
            fixed_terraform/
            checkov_reports/
          retention-days: 30
          if-no-files-found: warn

      - name: ğŸ¯ Set Job Status
        if: always()
        run: |
          if [ "${{ needs.security-scan.outputs.has-s3-issues }}" == "true" ]; then
            echo "âœ… S3 fixes generated successfully"
            exit 0
          else
            echo "â„¹ï¸ No S3 issues found - fixes generation skipped"
            exit 0
          fi

  # Job 3: Summary and Notifications  
  summary:
    name: ğŸ“‹ Workflow Summary
    runs-on: ubuntu-latest
    needs: [security-scan, generate-fixes]
    if: always()
    permissions:
      contents: read
      actions: read
    
    steps:
      - name: ğŸ“Š Generate Workflow Summary
        run: |
          echo "# ğŸ›¡ï¸ S3 Security Gatekeeper Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ğŸ“ˆ Job Results" >> $GITHUB_STEP_SUMMARY
          echo "- **Security Scan:** ${{ needs.security-scan.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Fix Generation:** ${{ needs.generate-fixes.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ğŸ” Scan Details" >> $GITHUB_STEP_SUMMARY
          echo "- **S3 Issues Found:** ${{ needs.security-scan.outputs.s3-issues-count || '0' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Has S3 Issues:** ${{ needs.security-scan.outputs.has-s3-issues || 'false' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Scan Status:** ${{ needs.security-scan.outputs.scan-status || 'unknown' }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ needs.security-scan.outputs.has-s3-issues }}" == "true" ]; then
            echo "## âš ï¸ Action Required" >> $GITHUB_STEP_SUMMARY
            echo "S3 security issues were detected. Please review the generated fixes in the artifacts." >> $GITHUB_STEP_SUMMARY
          else
            echo "## âœ… All Clear" >> $GITHUB_STEP_SUMMARY
            echo "No S3 security issues detected in this scan." >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ğŸ“ Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "- [Security Scan Results](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
          if [ "${{ needs.security-scan.outputs.has-s3-issues }}" == "true" ]; then
            echo "- [Generated S3 Fixes](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
          fi

      - name: ğŸš¨ Fail on Security Issues
        if: needs.security-scan.outputs.has-s3-issues == 'true' && github.event_name == 'push'
        run: |
          echo "âŒ Security issues detected in S3 configuration!"
          echo "Please review and apply the generated fixes before proceeding."
          exit 1